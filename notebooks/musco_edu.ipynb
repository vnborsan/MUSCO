{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d01894f",
   "metadata": {},
   "source": [
    "# *From Corpus to Classroom: Interactive Access to Childrenâ€™s Song Repertoires on the MUSCO Platform*\n",
    "## Authors: Vanessa Nina Borsan, Jure Juvan, Matija Marolt, MatevÅ¾ Pesek, Leon Stefanija\n",
    "### Presented as a poster @ ICCCM â€™25, 8-10 October 2025, Aalborg University, Aalborg, DENMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037348d",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ca6822",
   "metadata": {},
   "source": [
    "\n",
    "## The following notebook includes usage examples of scripts for:\n",
    "1. Data Preprocessing\n",
    "2. Data Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314752f2",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9cc0d",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd() / \"src\"))\n",
    "\n",
    "p = Path.cwd()\n",
    "while p != p.parent and not (p / \"src\").exists():\n",
    "    p = p.parent\n",
    "sys.path.insert(0, str(p / \"src\"))\n",
    "\n",
    "from educationalfilters import prepare_df\n",
    "from educationalfilters import save_load\n",
    "from educationalfilters.pipeline import apply_all_filters\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from educationalfilters import filter_label_utils as flu, filter_df\n",
    "importlib.reload(flu)\n",
    "importlib.reload(filter_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b62170",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ROOT = Path(p)                          \n",
    "RAW_DIR    = REPO_ROOT / \"data\" / \"raw\"\n",
    "PROC_DIR   = REPO_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "CIC_JSON_DIR = str((RAW_DIR / \"ciciban_jsons\").resolve())\n",
    "SLP_CSV      = str((RAW_DIR / \"slp_df.csv\").resolve())\n",
    "SLP_SCORES   = str((REPO_ROOT / \"scores/slp\").resolve())    # folder with .mxl files\n",
    "RHY_MAP_FILE = \"rhythm_mapping.pickle\"                      # lives in data/processed/ via save_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Ciciban DF from JSONs (notes-only rhythm, pause_count from JSON rhythm vs melody length)\n",
    "c_df = prepare_df.convert_jsons_to_df(CIC_JSON_DIR)\n",
    "# Upgrade to ABC using canonical map (creates/extends data/processed/rhythm_mapping.pickle)\n",
    "c_df, rhythm_mapping = prepare_df.df_upgrade(c_df, save_file_path=RHY_MAP_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84acd7",
   "metadata": {},
   "source": [
    "# PREPARE DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac101dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SLP CSV + parse .mxl rhythms/time sigs; apply canonical ABC mapping\n",
    "slp_df = prepare_df.prepare_slp(SLP_CSV, SLP_SCORES, RHY_MAP_FILE)\n",
    "\n",
    "# [Optional] harmonize a couple of fields if needed by downstream code\n",
    "if \"min_pitch\" in slp_df.columns and \"max_pitch\" in slp_df.columns:\n",
    "    slp_df[\"ambitus_min\"] = slp_df[\"ambitus_min\"].fillna(slp_df[\"min_pitch\"])\n",
    "    slp_df[\"ambitus_max\"] = slp_df[\"ambitus_max\"].fillna(slp_df[\"max_pitch\"])\n",
    "slp_df[\"time_signature_raw\"] = slp_df[\"time_signature\"].astype(\"string\")\n",
    "\n",
    "print(f\"{len(slp_df)} SLP rows\")\n",
    "display(slp_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09257bb8",
   "metadata": {},
   "source": [
    "## RHYTHM MAPPING REFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0ecb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from educationalfilters import save_load\n",
    "\n",
    "rhythm_mapping = save_load.load_pickle(\"rhythm_mapping.pickle\")\n",
    "\n",
    "print(\"ðŸŽ¼ Current Rhythm Mapping (duration â†’ letter) [FIXED: a (0.5), d (1.0), e (2.0); AUTOMATICALLY GENERATED: the rest]:\")\n",
    "pprint.pprint(dict(sorted(rhythm_mapping.items())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80f50b",
   "metadata": {},
   "source": [
    "## VRF & IF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_min_range='C4'\n",
    "pre_max_range='A4'\n",
    "pre_plus_min_range='A3'\n",
    "pre_plus_max_range='C5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3544e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_min_range      = 'C4'\n",
    "pre_max_range      = 'A4'\n",
    "pre_plus_min_range = 'A3'\n",
    "pre_plus_max_range = 'C5'\n",
    "\n",
    "# Apply to Ciciban\n",
    "ciciban_df = filter_df.preschool_filter(\n",
    "    c_df,\n",
    "    pre_plus_min_pitch=pre_plus_min_range,\n",
    "    pre_plus_max_pitch=pre_plus_max_range,\n",
    "    pre_min_pitch=pre_min_range,\n",
    "    pre_max_pitch=pre_max_range,\n",
    "    rhythm_mapping=rhythm_mapping,  # accepted but not required by RF\n",
    ")\n",
    "\n",
    "# Apply to SLP\n",
    "slp_df_f = filter_df.preschool_filter(\n",
    "    slp_df,\n",
    "    pre_plus_min_pitch=pre_plus_min_range,\n",
    "    pre_plus_max_pitch=pre_plus_max_range,\n",
    "    pre_min_pitch=pre_min_range,\n",
    "    pre_max_pitch=pre_max_range,\n",
    "    rhythm_mapping=rhythm_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d6d7a",
   "metadata": {},
   "source": [
    "## CONVERT RHYTHMS AND MELODIC INTERVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ada125",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[slp_df_f, ciciban_df]\n",
    "labels=['SLP', 'Ciciban']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from educationalfilters import dataset_conversion as dc, rfilters\n",
    "\n",
    "# Adapter so the new rfilters works with the old function signature\n",
    "def _rf_adapter(df, rhythm_mapping, label):\n",
    "    df2 = df.copy()\n",
    "    df2['corpus'] = label\n",
    "    return rfilters.compute_rhythm_labels(df2)  # -> (df_out, counts)\n",
    "\n",
    "KEEP_COLS = [\n",
    "    \"metadata_filename\", \"metadata_title\", \"corpus\",\n",
    "    \"melodic_string\", \"melodic_string_absolute\", \"melodic_string_abc\",\n",
    "    \"melodic_string_relative\", \"melodic_intervals\",\n",
    "    \"rhythm_string\", \"rhythm_string_abc\", \"time_signature\",\n",
    "    \"has_pauses\", \"pause_count\",\n",
    "    \"ambitus_min\", \"ambitus_max\", \"ambitus_semitones\", \"ambitus_interval\",\n",
    "    \"VRF_label\", \"IF_label\", \"RF_label\",\n",
    "    \"VRF_BOTH\", \"IF_BOTH\", \"RF_BOTH\",  # include only if you compute these earlier\n",
    "]\n",
    "\n",
    "merged_df, all_counts = dc.process_and_merge_dfs(\n",
    "    dfs, labels, rhythm_mapping, filter_function=_rf_adapter, keep_cols=KEEP_COLS\n",
    ")\n",
    "merged_df = dc.prepare_melodic_intervals(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns are not being used in this case study, so they were not considered and dropped from the df.\n",
    "drop_cols = [\"metadata_title\", \"melodic_string\", \"melodic_string_absolute\"]\n",
    "drop_cols = [c for c in drop_cols if c in merged_df.columns]  \n",
    "\n",
    "merged_df = merged_df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac7cc6",
   "metadata": {},
   "source": [
    "## DATA CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18312a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd() / \"src\"))\n",
    "\n",
    "from educationalfilters import filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94894024",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_clean = filter_df.prepare_all_filters_clean(merged_df)  # fixed row order for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9eb28",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# add the parent directory (project/) to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from scripts import plot\n",
    "\n",
    "COLORS  = ['#04795E', '#E9E9E9']  # Ciciban, SLP\n",
    "HATCHES = ['//', '\\\\\\\\']\n",
    "\n",
    "group1 = [\"VRF1\", \"IF1\", \"VRF2\", \"IF2\", \"VRF1 + IF1\", \"VRF2+IF2\", \"ANY (VRF+IF)\"]\n",
    "group2 = [\"RF1\", \"RF2\", \"RF3\", \"RF4\", \"VRF2+IF2+RF3\", \"VRF2+IF2+RF4\", \"ANY (VRF+IF+RF)\"]\n",
    "\n",
    "plot.plot_filters(summary_clean, COLORS, HATCHES, group1, group2, save_path=\"exports/filters_summary.png\")\n",
    "\n",
    "os.makedirs(\"exports\", exist_ok=True)\n",
    "summary_clean.to_csv(\"exports/filters_summary_clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (work_env)",
   "language": "python",
   "name": "work_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
